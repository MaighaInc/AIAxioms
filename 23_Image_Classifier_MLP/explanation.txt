Hello guys, welcome back to the channel.

In the previous videos,
we learned how neural networks work
and how backpropagation trains them.

Today we are doing something exciting.

Todayâ€™s topic is:
IMAGE CLASSIFIER USING MLP.

This is the first time
our neural network will work with images.

Now let me clarify something very important.

Computers do NOT see images
like humans.

An image is just numbers.

Each pixel is a number
representing intensity.

In our dataset,
each image is 8 by 8 pixels.

That means 64 numbers per image.

Now let us understand the problem.

We want to classify handwritten digits:
0 through 9.

This is a multi-class classification problem.

Now let us look at the code.

First,
we load the digits dataset.

Each image is flattened
into a vector of 64 values.

We normalize the data
to keep values between 0 and 1.

This helps training.

Next,
we convert labels into one-hot encoding.

This allows the network
to learn probabilities
for each digit.

Now let us look at the network.

We use a multilayer perceptron.

Input layer has 64 neurons.
Hidden layer has 64 neurons.
Output layer has 10 neurons.

We use ReLU activation
in the hidden layer.

ReLU helps the network
learn complex patterns.

At the output layer,
we use softmax.

Softmax converts outputs
into probabilities.

Now let us talk about training.

The network performs forward propagation,
calculates loss using cross-entropy,
and updates weights using backpropagation.

You will see
the loss decreasing steadily.

After training,
we test the model
on unseen images.

The model achieves
around 90 percent accuracy.

This is amazing,
considering we did not use CNNs.

But there is a limitation.

MLPs do not understand
spatial structure of images.

They treat images
as flat vectors.

This is inefficient
for real-world images.

That is why
Convolutional Neural Networks exist.

In the next video,
we will build a CNN
for digit recognition.

This is where deep learning
starts to feel powerful.

Thank you for watching.
See you in the next video.
