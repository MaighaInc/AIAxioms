Safety-Filtered LLM
==================

This project demonstrates how
AI systems enforce safety rules
during interaction.

Requirements:
------------
- Python 3.x

How to Run:
-----------
1. Open terminal
2. Navigate to this folder
3. Run:

   python safety_filtered_llm.py

Expected Output:
----------------
- Safe response for allowed prompts
- Warning message for unsafe prompts

Learning Objective:
-------------------
Understand how responsible AI
is implemented in real systems.
